<<<<<<< Updated upstream
# ğŸ¤– AI-Powered Multi-Scraper Dashboard

A powerful Streamlit application that combines web scraping capabilities with AI-powered natural language processing to make data extraction as simple as having a conversation.

## âœ¨ Features

### ğŸ¯ AI-Powered Chat Interface
- **Natural Language Processing**: Chat with the AI to run scrapers using everyday language
- **Intent Recognition**: Automatically detects which scraper to use based on your request
- **Smart Parameter Extraction**: AI understands and extracts relevant parameters from your messages
- **Gemini AI Integration**: Powered by Google's Gemini 2.0 Flash for intelligent conversation

### ğŸ•¸ï¸ Multi-Platform Scraping
- **Instagram**: Scrape posts by hashtags and user profiles
- **Booking.com**: Extract hotel information, prices, and reviews
- **Twitter/X**: Gather tweets, search terms, and user content
- **Google Maps**: Find places, businesses, and location data
- **Website Content**: Extract and parse web page content
- **Facebook**: Scrape Facebook posts and profiles
- **Google News**: Gather news articles and headlines
- **TripAdvisor**: Extract reviews and business information

### ğŸ“Š Rich Data Visualization
- **Interactive Dashboards**: View results in beautiful, interactive tables
- **Data Export**: Download results as CSV or JSON files
- **Real-time Analytics**: Get instant summaries and statistics
- **Filtering & Sorting**: Advanced data manipulation capabilities

## ğŸš€ Quick Start

### Prerequisites
- Python 3.13 or higher
- Apify API token
- Gemini API key (optional, for AI features)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd new-streamlit
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   # or using uv (recommended)
   uv sync
   ```

3. **Set up API keys**
   - Get your [Apify API token](https://console.apify.com/account/integrations)
   - Get your [Gemini API key](https://makersuite.google.com/app/apikey) (optional)

4. **Run the application**
   ```bash
   streamlit run app.py
   ```

## ğŸ’¬ How to Use

### AI Chatbot Interface

Simply chat with the AI using natural language:

```
User: "Find hotels in Paris on Booking.com"
AI: ğŸ¯ Intent Detected: Searching for hotels in Paris on Booking.com
     âœ… Booking.com Scraping Complete!
     ğŸ¨ Summary: 10 hotels found in Paris
     Price Range: $50 - $500 USD
```

**Example Conversations:**
- "Scrape Instagram posts with hashtag #travel"
- "Get tweets from @elonmusk about AI"
- "Find restaurants in New York on Google Maps"
- "Extract content from https://docs.apify.com"
- "Search for hotels in Tokyo with max 15 results"

### Manual Dashboard

For advanced users, use the manual dashboard to:
- Configure scraping parameters directly
- View detailed results and analytics
- Export data in multiple formats
- Filter and sort results

## ğŸ”§ Available Scrapers

### ğŸ“± Instagram Scrapers
- **Hashtag Scraper**: Extract posts by hashtags
  - Parameters: hashtags, results_limit
  - Example: `["#travel", "#photography"]`
- **Profile Scraper**: Scrape user profile posts
  - Parameters: profile_urls, results_limit
  - Example: `["https://instagram.com/username"]`

### ğŸ¨ Booking.com Scraper
- **Hotel Search**: Find hotels with detailed information
  - Parameters: search, max_items, currency, rooms, adults, children, min_max_price
  - Example: `search="New York", max_items=10, currency="USD"`

### ğŸ¦ Twitter/X Scraper
- **Tweet Extraction**: Gather tweets and user content
  - Parameters: start_urls, search_terms, twitter_handles, max_items
  - Example: `twitter_handles=["@elonmusk"], max_items=20`

### ğŸŒ Website Content Scraper
- **Content Extraction**: Parse and extract web page content
  - Parameters: start_urls, results_limit, save_markdown
  - Example: `start_urls=["https://docs.apify.com"]`

### ğŸ“ Google Maps Scraper
- **Place Search**: Find businesses and locations
  - Parameters: search_strings, location_query, max_places
  - Example: `search_strings=["restaurant"], location_query="New York, USA"`

## ğŸ“Š Data Output

Each scraper returns structured data including:

- **Summary Statistics**: Total items, unique users, engagement metrics
- **Detailed Results**: Complete data with all extracted fields
- **Export Options**: CSV and JSON download capabilities
- **Visual Analytics**: Interactive charts and tables

## ğŸ› ï¸ Technical Architecture

### Core Technologies
- **Streamlit**: Web application framework
- **Apify**: Web scraping platform with pre-built actors
- **Gemini AI**: Natural language processing and intent recognition
- **Pandas**: Data manipulation and analysis
- **Plotly**: Interactive data visualization

### Project Structure
```
new-streamlit/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ apifyActors/          # Scraper modules
â”‚   â”œâ”€â”€ instagram_hashtage.py
â”‚   â”œâ”€â”€ instagram.py
â”‚   â”œâ”€â”€ booking.py
â”‚   â”œâ”€â”€ tweet.py
â”‚   â”œâ”€â”€ website_content.py
â”‚   â”œâ”€â”€ google_maps.py
â”‚   â”œâ”€â”€ facebook.py
â”‚   â”œâ”€â”€ google_news.py
â”‚   â””â”€â”€ trip_advisor.py
â”œâ”€â”€ pyproject.toml        # Project dependencies
â””â”€â”€ README.md            # This file
```

## ğŸ”‘ API Configuration

### Required APIs

1. **Apify API Token**
   - Sign up at [Apify Console](https://console.apify.com/)
   - Navigate to Account â†’ Integrations â†’ API tokens
   - Copy your token and paste it in the app

2. **Gemini API Key** (Optional)
   - Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
   - Create a new API key
   - Enable the Gemini API in your Google Cloud Console

## ğŸ¨ Features in Detail

### AI Chatbot Capabilities
- **Natural Language Understanding**: Processes complex requests in plain English
- **Context Awareness**: Remembers conversation history and preferences
- **Error Handling**: Provides helpful suggestions when requests fail
- **Multi-Modal Support**: Handles various input formats and parameters

### Data Processing
- **Real-time Processing**: Instant results with progress indicators
- **Data Validation**: Ensures data quality and completeness
- **Format Conversion**: Automatic conversion between data formats
- **Error Recovery**: Graceful handling of API failures and timeouts

### User Experience
- **Responsive Design**: Works on desktop and mobile devices
- **Dark/Light Mode**: Automatic theme detection
- **Keyboard Shortcuts**: Quick access to common functions
- **Export Options**: Multiple download formats (CSV, JSON, Excel)

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit your changes**: `git commit -m 'Add amazing feature'`
4. **Push to the branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Development Setup
```bash
# Clone the repository
git clone <repository-url>
cd new-streamlit

# Install development dependencies
uv sync --dev

# Run in development mode
streamlit run app.py --server.port 8501
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Apify**: For providing powerful web scraping actors
- **Google**: For the Gemini AI platform
- **Streamlit**: For the excellent web app framework
- **Open Source Community**: For the amazing tools and libraries

## ğŸ“ Support

- **Issues**: Report bugs and request features on GitHub
- **Discussions**: Join community discussions for help and ideas
- **Documentation**: Check the inline help and tooltips in the app

## ğŸ”® Roadmap

- [ ] Add more scraping platforms (LinkedIn, TikTok, etc.)
- [ ] Implement advanced analytics and reporting
- [ ] Add scheduled scraping capabilities
- [ ] Create mobile app version
- [ ] Add team collaboration features
- [ ] Implement data visualization dashboards

---

**Made with â¤ï¸ for the data community**

*Transform your web scraping workflow with AI-powered intelligence!*
=======
# ğŸ¤– AI-Powered Multi-Scraper Dashboard

A powerful Streamlit application that combines web scraping capabilities with AI-powered natural language processing to make data extraction as simple as having a conversation.

## âœ¨ Features

### ğŸ¯ AI-Powered Chat Interface
- **Natural Language Processing**: Chat with the AI to run scrapers using everyday language
- **Intent Recognition**: Automatically detects which scraper to use based on your request
- **Smart Parameter Extraction**: AI understands and extracts relevant parameters from your messages
- **Gemini AI Integration**: Powered by Google's Gemini 2.0 Flash for intelligent conversation

### ğŸ•¸ï¸ Multi-Platform Scraping
- **Instagram**: Scrape posts by hashtags and user profiles
- **Booking.com**: Extract hotel information, prices, and reviews
- **Twitter/X**: Gather tweets, search terms, and user content
- **Google Maps**: Find places, businesses, and location data
- **Website Content**: Extract and parse web page content
- **Facebook**: Scrape Facebook posts and profiles
- **Google News**: Gather news articles and headlines
- **TripAdvisor**: Extract reviews and business information

### ğŸ“Š Rich Data Visualization
- **Interactive Dashboards**: View results in beautiful, interactive tables
- **Data Export**: Download results as CSV or JSON files
- **Real-time Analytics**: Get instant summaries and statistics
- **Filtering & Sorting**: Advanced data manipulation capabilities

## ğŸš€ Quick Start

### Prerequisites
- Python 3.13 or higher
- Apify API token
- Gemini API key (optional, for AI features)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd new-streamlit
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   # or using uv (recommended)
   uv sync
   ```

3. **Set up API keys**
   - Get your [Apify API token](https://console.apify.com/account/integrations)
   - Get your [Gemini API key](https://makersuite.google.com/app/apikey) (optional)

4. **Run the application**
   ```bash
   streamlit run app.py
   ```

## ğŸ’¬ How to Use

### AI Chatbot Interface

Simply chat with the AI using natural language:

```
User: "Find hotels in Paris on Booking.com"
AI: ğŸ¯ Intent Detected: Searching for hotels in Paris on Booking.com
     âœ… Booking.com Scraping Complete!
     ğŸ¨ Summary: 10 hotels found in Paris
     Price Range: $50 - $500 USD
```

**Example Conversations:**
- "Scrape Instagram posts with hashtag #travel"
- "Get tweets from @elonmusk about AI"
- "Find restaurants in New York on Google Maps"
- "Extract content from https://docs.apify.com"
- "Search for hotels in Tokyo with max 15 results"

### Manual Dashboard

For advanced users, use the manual dashboard to:
- Configure scraping parameters directly
- View detailed results and analytics
- Export data in multiple formats
- Filter and sort results

## ğŸ”§ Available Scrapers

### ğŸ“± Instagram Scrapers
- **Hashtag Scraper**: Extract posts by hashtags
  - Parameters: hashtags, results_limit
  - Example: `["#travel", "#photography"]`
- **Profile Scraper**: Scrape user profile posts
  - Parameters: profile_urls, results_limit
  - Example: `["https://instagram.com/username"]`

### ğŸ¨ Booking.com Scraper
- **Hotel Search**: Find hotels with detailed information
  - Parameters: search, max_items, currency, rooms, adults, children, min_max_price
  - Example: `search="New York", max_items=10, currency="USD"`

### ğŸ¦ Twitter/X Scraper
- **Tweet Extraction**: Gather tweets and user content
  - Parameters: start_urls, search_terms, twitter_handles, max_items
  - Example: `twitter_handles=["@elonmusk"], max_items=20`

### ğŸŒ Website Content Scraper
- **Content Extraction**: Parse and extract web page content
  - Parameters: start_urls, results_limit, save_markdown
  - Example: `start_urls=["https://docs.apify.com"]`

### ğŸ“ Google Maps Scraper
- **Place Search**: Find businesses and locations
  - Parameters: search_strings, location_query, max_places
  - Example: `search_strings=["restaurant"], location_query="New York, USA"`

## ğŸ“Š Data Output

Each scraper returns structured data including:

- **Summary Statistics**: Total items, unique users, engagement metrics
- **Detailed Results**: Complete data with all extracted fields
- **Export Options**: CSV and JSON download capabilities
- **Visual Analytics**: Interactive charts and tables

## ğŸ› ï¸ Technical Architecture

### Core Technologies
- **Streamlit**: Web application framework
- **Apify**: Web scraping platform with pre-built actors
- **Gemini AI**: Natural language processing and intent recognition
- **Pandas**: Data manipulation and analysis
- **Plotly**: Interactive data visualization

### Project Structure
```
new-streamlit/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ apifyActors/          # Scraper modules
â”‚   â”œâ”€â”€ instagram_hashtage.py
â”‚   â”œâ”€â”€ instagram.py
â”‚   â”œâ”€â”€ booking.py
â”‚   â”œâ”€â”€ tweet.py
â”‚   â”œâ”€â”€ website_content.py
â”‚   â”œâ”€â”€ google_maps.py
â”‚   â”œâ”€â”€ facebook.py
â”‚   â”œâ”€â”€ google_news.py
â”‚   â””â”€â”€ trip_advisor.py
â”œâ”€â”€ pyproject.toml        # Project dependencies
â””â”€â”€ README.md            # This file
```

## ğŸ”‘ API Configuration

### Required APIs

1. **Apify API Token**
   - Sign up at [Apify Console](https://console.apify.com/)
   - Navigate to Account â†’ Integrations â†’ API tokens
   - Copy your token and paste it in the app

2. **Gemini API Key** (Optional)
   - Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
   - Create a new API key
   - Enable the Gemini API in your Google Cloud Console

## ğŸ¨ Features in Detail

### AI Chatbot Capabilities
- **Natural Language Understanding**: Processes complex requests in plain English
- **Context Awareness**: Remembers conversation history and preferences
- **Error Handling**: Provides helpful suggestions when requests fail
- **Multi-Modal Support**: Handles various input formats and parameters

### Data Processing
- **Real-time Processing**: Instant results with progress indicators
- **Data Validation**: Ensures data quality and completeness
- **Format Conversion**: Automatic conversion between data formats
- **Error Recovery**: Graceful handling of API failures and timeouts

### User Experience
- **Responsive Design**: Works on desktop and mobile devices
- **Dark/Light Mode**: Automatic theme detection
- **Keyboard Shortcuts**: Quick access to common functions
- **Export Options**: Multiple download formats (CSV, JSON, Excel)

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit your changes**: `git commit -m 'Add amazing feature'`
4. **Push to the branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Development Setup
```bash
# Clone the repository
git clone <repository-url>
cd new-streamlit

# Install development dependencies
uv sync --dev

# Run in development mode
streamlit run app.py --server.port 8501
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Apify**: For providing powerful web scraping actors
- **Google**: For the Gemini AI platform
- **Streamlit**: For the excellent web app framework
- **Open Source Community**: For the amazing tools and libraries

## ğŸ“ Support

- **Issues**: Report bugs and request features on GitHub
- **Discussions**: Join community discussions for help and ideas
- **Documentation**: Check the inline help and tooltips in the app

## ğŸ”® Roadmap

- [ ] Add more scraping platforms (LinkedIn, TikTok, etc.)
- [ ] Implement advanced analytics and reporting
- [ ] Add scheduled scraping capabilities
- [ ] Create mobile app version
- [ ] Add team collaboration features
- [ ] Implement data visualization dashboards

---

**Made with â¤ï¸ for the data community**

*Transform your web scraping workflow with AI-powered intelligence!*
>>>>>>> Stashed changes
